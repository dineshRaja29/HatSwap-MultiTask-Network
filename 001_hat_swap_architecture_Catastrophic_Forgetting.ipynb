{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshRaja29/SpeechArchitectures_Hat-Swap-Architecture/blob/main/001_hat_swap_architecture_Catastrophic_Forgetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>GOAL:</b></font>"
      ],
      "metadata": {
        "id": "ISucixaZsu_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Build a Hat Swap network for different datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "XKZWcqv_tCA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color = 'green'><b>Hat Swap Network:</b></font> Network with an output layer for each task (or dataset), but shared hidden layers.\n",
        "\n",
        "* Reference: https://www.inf.ed.ac.uk/teaching/courses/asr/2019-20/asr14-multiling.pdf"
      ],
      "metadata": {
        "id": "O_8VZiMeth-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>OBJECTIVES:</b></font>"
      ],
      "metadata": {
        "id": "IDbJFdzMt-EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The main goal is to build the Hat Swap architecture.\n",
        "* This architecture is primarily used in multilingual acoustic models, where it leverages feature correlations across different languages.\n",
        "* It can also be widely applied in any scenario involving correlated features between different tasks.\n",
        "* We implement this architecture on image-based tasks, where the images exhibit some degree of feature correlation across tasks.\n",
        "* To extract features from image, we used DINO (self-supervised ViT model from Facebook AI) model\n",
        "* The output is different for different tasks but have common hidden layers"
      ],
      "metadata": {
        "id": "iYrk9mc3ud7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>DATASET</b></font>"
      ],
      "metadata": {
        "id": "mlC-rCaq0ZsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Considering the CIFAR10 dataset as our base dataset\n",
        "* From CIFAR10, created three task's dataset\n",
        "    * with one: All images with label as 1 considered as 1 and images with label as 4 and 7 are considered as 0\n",
        "    * with two: All images with label as 2 considered as 1 and images with label as 5 and 6 are considered as 0\n",
        "    * with three: All images with label as 3 considered as 1 and images with label as 8 and 9 are considered as 0"
      ],
      "metadata": {
        "id": "IhqPdZRK0jEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>DATASET PREPARATION</b></font>"
      ],
      "metadata": {
        "id": "INFQwBZF1dg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToPILImage\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoFeatureExtractor, Dinov2Model\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# note: PIL stands for pillow; to install type \"pip3 install pillow\"\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from torchvision.transforms import Compose, Resize, RandomResizedCrop, RandomHorizontalFlip, ColorJitter, ToTensor, Normalize\n",
        "import numpy as np\n",
        "import os, gc"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:27:09.520873Z",
          "iopub.execute_input": "2025-07-29T06:27:09.521166Z",
          "iopub.status.idle": "2025-07-29T06:27:13.061972Z",
          "shell.execute_reply.started": "2025-07-29T06:27:09.521143Z",
          "shell.execute_reply": "2025-07-29T06:27:13.061309Z"
        },
        "id": "9so0Jyh9rW4g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple transformation\n",
        "transform = transforms.ToTensor()\n",
        "to_pil = ToPILImage()\n",
        "# download data\n",
        "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# intermediate directories to save data\n",
        "save_root = '/content/drive/MyDrive/cifar10_binary'\n",
        "os.makedirs(save_root, exist_ok = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:27:13.063173Z",
          "iopub.execute_input": "2025-07-29T06:27:13.063503Z",
          "iopub.status.idle": "2025-07-29T06:27:14.68099Z",
          "shell.execute_reply.started": "2025-07-29T06:27:13.063476Z",
          "shell.execute_reply": "2025-07-29T06:27:14.680374Z"
        },
        "id": "6GE4UHNyrW44"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def label_adjustment(dataset, pos, neg):\n",
        "    results = []\n",
        "    for img, label in dataset:\n",
        "        if label == pos:\n",
        "            results.append([img, 1])\n",
        "        if label in neg:\n",
        "             results.append([img, 0])\n",
        "    return results\n",
        "\n",
        "def save_images_and_make_csv(data, split_name):\n",
        "    dir = os.path.join(save_root, split_name)\n",
        "    os.makedirs(dir, exist_ok = True)\n",
        "    rows = []\n",
        "    for idx, (img_tensor, label) in enumerate(data):\n",
        "        img_path = os.path.join(dir, f'{idx}.png')\n",
        "        to_pil(img_tensor).save(img_path)\n",
        "        rows.append([img_path, label])\n",
        "\n",
        "    df = pd.DataFrame(rows, columns = [\"MD5HASH\", \"LABEL\"])\n",
        "    df.to_csv(os.path.join(save_root, f\"{split_name}.csv\"), index = False)\n",
        "    print(f\"{split_name}.csv saved with {len(rows)} entries.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:27:14.681692Z",
          "iopub.execute_input": "2025-07-29T06:27:14.681935Z",
          "iopub.status.idle": "2025-07-29T06:27:14.688339Z",
          "shell.execute_reply.started": "2025-07-29T06:27:14.681916Z",
          "shell.execute_reply": "2025-07-29T06:27:14.687759Z"
        },
        "id": "oPIh7hYlrW46"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multiple_csv_files():\n",
        "    labels = {\n",
        "             'with_one': [1, [4,7]],\n",
        "             'with_two': [2, [5,6]],\n",
        "             'with_three': [3, [8,9]]\n",
        "            }\n",
        "    for k, v in labels.items():\n",
        "        train_data = label_adjustment(train_set, v[0], v[1])\n",
        "        test_data  = label_adjustment(test_set, v[0], v[1])\n",
        "        # Save both splits\n",
        "        save_images_and_make_csv(train_data, f\"{k}_train\")\n",
        "        save_images_and_make_csv(test_data, f\"{k}_test\")\n",
        "\n",
        "generate_multiple_csv_files()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:27:14.689896Z",
          "iopub.execute_input": "2025-07-29T06:27:14.690346Z",
          "iopub.status.idle": "2025-07-29T06:28:00.909833Z",
          "shell.execute_reply.started": "2025-07-29T06:27:14.690325Z",
          "shell.execute_reply": "2025-07-29T06:28:00.909167Z"
        },
        "id": "3V_FtgMKrW5A",
        "outputId": "c9a9d9e5-4dd3-4d8a-e2aa-16543dcdea0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "with_one_train.csv saved with 15000 entries.\nwith_one_test.csv saved with 3000 entries.\nwith_two_train.csv saved with 15000 entries.\nwith_two_test.csv saved with 3000 entries.\nwith_three_train.csv saved with 15000 entries.\nwith_three_test.csv saved with 3000 entries.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/cifar10_binary/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:00.910511Z",
          "iopub.execute_input": "2025-07-29T06:28:00.91072Z",
          "iopub.status.idle": "2025-07-29T06:28:01.069064Z",
          "shell.execute_reply.started": "2025-07-29T06:28:00.910702Z",
          "shell.execute_reply": "2025-07-29T06:28:01.068102Z"
        },
        "id": "YCYWp21UrW5E",
        "outputId": "4ce9c78f-e6fc-4ee8-8372-ea4724e6b872"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "with_one_test\t    with_three_test\t  with_two_test\nwith_one_test.csv   with_three_test.csv   with_two_test.csv\nwith_one_train\t    with_three_train\t  with_two_train\nwith_one_train.csv  with_three_train.csv  with_two_train.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "! cat /content/drive/MyDrive/cifar10_binary/with_two_train.csv | head -4"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:01.070253Z",
          "iopub.execute_input": "2025-07-29T06:28:01.070513Z",
          "iopub.status.idle": "2025-07-29T06:28:01.220586Z",
          "shell.execute_reply.started": "2025-07-29T06:28:01.070478Z",
          "shell.execute_reply": "2025-07-29T06:28:01.219807Z"
        },
        "id": "LK8tbLW-rW5N",
        "outputId": "06a10a72-04f1-4ed3-ad76-233339aa6c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "MD5HASH,LABEL\n/content/drive/MyDrive/cifar10_binary/with_two_train/0.png,0\n/content/drive/MyDrive/cifar10_binary/with_two_train/1.png,1\n/content/drive/MyDrive/cifar10_binary/with_two_train/2.png,1\ncat: write error: Broken pipe\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>SETTING ENVIRONMENT FOR HARDWARE ACCELERATOR</b></font>"
      ],
      "metadata": {
        "id": "vks10OIm106H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for CUDA and MPS availability, set the device accordingly\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    # setting environment variables, need to run training in MacOS\n",
        "    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
        "    os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "    print(\"Using MPS as the device.\")\n",
        "else:\n",
        "    if torch.cuda.is_available():\n",
        "\t# the syntax 'cuda:3' used to point a specific GPU from the cluster of GPUs\n",
        "\t# 'cuda' points to first GPU from the cluster of GPUs\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"Using CUDA as the device.\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU as the device.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:06.49578Z",
          "iopub.execute_input": "2025-07-29T06:28:06.496228Z",
          "iopub.status.idle": "2025-07-29T06:28:06.501304Z",
          "shell.execute_reply.started": "2025-07-29T06:28:06.496208Z",
          "shell.execute_reply": "2025-07-29T06:28:06.50067Z"
        },
        "id": "kX9g4mi2rW5S",
        "outputId": "3d4794e9-6629-4bd3-90ad-76b170913eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using CUDA as the device.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>CONFIGURATION VARIABLES</b></font>"
      ],
      "metadata": {
        "id": "tcLox8MU2HXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE                            = 128 #256\n",
        "WORKERS                               = 4\n",
        "PIN_MEMORY                            = True\n",
        "MIXING                                = True\n",
        "MODEL_NAME                            = \"facebook/dinov2-base\"\n",
        "RESULTS                               = 'results'\n",
        "EPOCHS                                = 5\n",
        "BEST_MODEL                            = None\n",
        "PRETRAINING                           = False\n",
        "LEARNING_RATE                         = 1e-4\n",
        "L2_PENALTY                            = 1e-4\n",
        "GAMMA                                 = 0.1\n",
        "STEPSIZE                              = 3\n",
        "SAVE_CHECKPOINTS                      = True\n",
        "MIN_LOSS                              = float('inf')\n",
        "MODEL_SAVED                           = f'{RESULTS}/bestmodel.pth'\n",
        "THRESHOLD                             = 0.5\n",
        "OUTPUT_DIM                            = 1\n",
        "HEADS                                 = ['with_one', 'with_two', 'with_three']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:06.502053Z",
          "iopub.execute_input": "2025-07-29T06:28:06.502289Z",
          "iopub.status.idle": "2025-07-29T06:28:06.51837Z",
          "shell.execute_reply.started": "2025-07-29T06:28:06.502267Z",
          "shell.execute_reply": "2025-07-29T06:28:06.517766Z"
        },
        "id": "vv7mK_3urW5T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_classification_accuracy(loader, model, head):\n",
        "    model.eval()  # Set the model in evaluation mode\n",
        "    LABELS = []\n",
        "    PREDICTIONS = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            # Move to device and cast to float32\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "            probabilities = model(images, head).squeeze()\n",
        "            # Predictions based on the threshold\n",
        "            prediction = torch.where(probabilities > THRESHOLD, 1.0, 0.0)\n",
        "            LABELS.extend(labels.tolist())\n",
        "            PREDICTIONS.extend(prediction.tolist())\n",
        "    return classification_report(LABELS, PREDICTIONS)\n",
        "\n",
        "\n",
        "def cleaning_memory():\n",
        "    # Explicitly free up GPU memory\n",
        "    if torch.backends.mps.is_available():\n",
        "        torch.backends.mps.is_macos13_or_newer.cache_clear()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    # Run garbage collector to free up CPU memory\n",
        "    gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:06.520599Z",
          "iopub.execute_input": "2025-07-29T06:28:06.520797Z",
          "iopub.status.idle": "2025-07-29T06:28:06.535672Z",
          "shell.execute_reply.started": "2025-07-29T06:28:06.520782Z",
          "shell.execute_reply": "2025-07-29T06:28:06.535117Z"
        },
        "id": "qxN8I1XNrW5Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>MODEL ARCHITECTURE</b></font>"
      ],
      "metadata": {
        "id": "8y4ZLaEA2Rda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Taking DINO as feature extractor which we will fine-tune on our dataset."
      ],
      "metadata": {
        "id": "ZOygqae42W5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadNetwork(nn.Module):\n",
        "    # Reference: https://www.inf.ed.ac.uk/teaching/courses/asr/2019-20/asr14-multiling.pdf\n",
        "    def __init__(self, heads):\n",
        "        super(MultiHeadNetwork, self).__init__()\n",
        "\n",
        "        # Load pre-trained processor and backbone model\n",
        "        # taking processor for necessary substitions, if needed in later stages\n",
        "        self.processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
        "        self.backbone_model = Dinov2Model.from_pretrained(MODEL_NAME)\n",
        "        self.pretrained_backbone_model_last_dim = self.backbone_model.layernorm.normalized_shape[0]\n",
        "\n",
        "        # Create a dictionary to hold the heads\n",
        "        self.heads = nn.ModuleDict()\n",
        "\n",
        "        for head in heads:\n",
        "            # Create a classification head for each entry in heads\n",
        "            self.heads[head] = nn.Sequential(\n",
        "                nn.Linear(self.pretrained_backbone_model_last_dim, OUTPUT_DIM, bias=True),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        # Initialize weights\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        torch.manual_seed(444)\n",
        "        for head_name, head in self.heads.items():\n",
        "            for layer in head:\n",
        "                if isinstance(layer, nn.Linear):\n",
        "                    nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
        "                    nn.init.zeros_(layer.bias)\n",
        "                    print(f\"kaiming_uniform_ Initialization: {layer.__class__.__name__}\")\n",
        "\n",
        "    def forward(self, x, head):\n",
        "        # Pass input through the backbone model\n",
        "        x = self.backbone_model(x).last_hidden_state[:, 0]\n",
        "        # Pass the output through the corresponding head\n",
        "        x = self.heads[head](x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:06.536343Z",
          "iopub.execute_input": "2025-07-29T06:28:06.536508Z",
          "iopub.status.idle": "2025-07-29T06:28:06.55128Z",
          "shell.execute_reply.started": "2025-07-29T06:28:06.536495Z",
          "shell.execute_reply": "2025-07-29T06:28:06.550547Z"
        },
        "id": "mihIhxn0rW5b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiHeadNetwork(HEADS)\n",
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:06.551983Z",
          "iopub.execute_input": "2025-07-29T06:28:06.552181Z",
          "iopub.status.idle": "2025-07-29T06:28:07.237626Z",
          "shell.execute_reply.started": "2025-07-29T06:28:06.552166Z",
          "shell.execute_reply": "2025-07-29T06:28:07.236874Z"
        },
        "id": "3qhFeGnprW5g",
        "outputId": "9ae4a266-974b-4a37-fcc1-7776812e2e5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kaiming_uniform_ Initialization: Linear\nkaiming_uniform_ Initialization: Linear\nkaiming_uniform_ Initialization: Linear\n",
          "output_type": "stream"
        },
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "MultiHeadNetwork(\n  (backbone_model): Dinov2Model(\n    (embeddings): Dinov2Embeddings(\n      (patch_embeddings): Dinov2PatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): Dinov2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x Dinov2Layer(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attention): Dinov2Attention(\n            (attention): Dinov2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (output): Dinov2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (layer_scale1): Dinov2LayerScale()\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): Dinov2MLP(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (activation): GELUActivation()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_scale2): Dinov2LayerScale()\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  )\n  (heads): ModuleDict(\n    (with_one): Sequential(\n      (0): Linear(in_features=768, out_features=1, bias=True)\n      (1): Sigmoid()\n    )\n    (with_two): Sequential(\n      (0): Linear(in_features=768, out_features=1, bias=True)\n      (1): Sigmoid()\n    )\n    (with_three): Sequential(\n      (0): Linear(in_features=768, out_features=1, bias=True)\n      (1): Sigmoid()\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>DATASET LOADING</b></font>"
      ],
      "metadata": {
        "id": "bSYWR5_F2kAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MD5HASHDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.images = self.dataframe['MD5HASH'].values\n",
        "        self.labels = self.dataframe['LABEL'].values\n",
        "        self.processor = model.processor\n",
        "        self.mean = self.processor.image_mean\n",
        "        self.std = self.processor.image_std\n",
        "        self.interpolation = self.processor.resample\n",
        "\n",
        "        self.train_transform = Compose([\n",
        "            Resize(size = (32, 32)),\n",
        "            #RandomResizedCrop(size = (224, 224),\n",
        "            #                  scale = (0.08, 1.0),\n",
        "            #                  ratio = (0.75, 1.3333),\n",
        "            #                  interpolation = self.interpolation),\n",
        "            #RandomHorizontalFlip(p = 0.5),\n",
        "            #ColorJitter(brightness = (0.6, 1.4),\n",
        "            #            contrast = (0.6, 1.4),\n",
        "            #            saturation = (0.6, 1.4)),\n",
        "            ToTensor(),\n",
        "            Normalize(mean = self.mean, std = self.std),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load the image from the file path\n",
        "        image_path = self.images[idx]\n",
        "        image = self.train_transform(Image.open(image_path).convert('RGB'))\n",
        "        # Get the label\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:07.238449Z",
          "iopub.execute_input": "2025-07-29T06:28:07.238673Z",
          "iopub.status.idle": "2025-07-29T06:28:07.24446Z",
          "shell.execute_reply.started": "2025-07-29T06:28:07.238656Z",
          "shell.execute_reply": "2025-07-29T06:28:07.243783Z"
        },
        "id": "2kQiPaUBrW5i"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_loader(data_csv, upsampling = False):\n",
        "    # Load data\n",
        "    training_data = pd.read_csv(data_csv)\n",
        "    print('::: DATA DETAILS :::')\n",
        "    print('- Number of Samples:', training_data.shape[0])\n",
        "    print('- LABEL DISTRIBUTION: \\n',training_data['LABEL'].value_counts())\n",
        "    # Create dataset and dataloader\n",
        "    md5hash_dataset = MD5HASHDataset(training_data)\n",
        "    if upsampling:\n",
        "        # References:\n",
        "        # https://pytorch.org/docs/stable/data.html\n",
        "        # https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452\n",
        "        from torch.utils.data import WeightedRandomSampler\n",
        "        classes_count = dict(training_data['LABEL'].value_counts())\n",
        "        sample_weights = [ 1 / classes_count[i] for i in training_data.LABEL.values]\n",
        "        sampler = WeightedRandomSampler(weights = sample_weights,\n",
        "                                        num_samples = len(training_data),\n",
        "                                        replacement = True)\n",
        "        data_loader = DataLoader(md5hash_dataset,\n",
        "                                 batch_size = BATCH_SIZE,\n",
        "                                 num_workers = WORKERS,\n",
        "                                 pin_memory = PIN_MEMORY,\n",
        "                                 shuffle = False,\n",
        "                                 sampler = sampler)\n",
        "    else:\n",
        "        data_loader = DataLoader(md5hash_dataset,\n",
        "                                 batch_size = BATCH_SIZE,\n",
        "                                 num_workers = WORKERS,\n",
        "                                 pin_memory = PIN_MEMORY,\n",
        "                                 shuffle = MIXING)\n",
        "\n",
        "    # Clean memory, :)\n",
        "    del training_data\n",
        "\n",
        "    return data_loader"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:07.245371Z",
          "iopub.execute_input": "2025-07-29T06:28:07.245674Z",
          "iopub.status.idle": "2025-07-29T06:28:07.262492Z",
          "shell.execute_reply.started": "2025-07-29T06:28:07.245657Z",
          "shell.execute_reply": "2025-07-29T06:28:07.261899Z"
        },
        "id": "ifGxoQB-rW5j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>LOSS FUNCTION</b></font>"
      ],
      "metadata": {
        "id": "bIgqbrdZ2q-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function: BCE\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:07.263362Z",
          "iopub.execute_input": "2025-07-29T06:28:07.263553Z",
          "iopub.status.idle": "2025-07-29T06:28:07.278661Z",
          "shell.execute_reply.started": "2025-07-29T06:28:07.263538Z",
          "shell.execute_reply": "2025-07-29T06:28:07.277998Z"
        },
        "id": "Y1eU9LatrW5o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# directory creation\n",
        "os.makedirs(RESULTS, exist_ok = True)\n",
        "if SAVE_CHECKPOINTS:\n",
        "    CHECKPOINTDIR = f'{RESULTS}/checkpoints'\n",
        "    os.makedirs(CHECKPOINTDIR, exist_ok = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:07.279327Z",
          "iopub.execute_input": "2025-07-29T06:28:07.279549Z",
          "iopub.status.idle": "2025-07-29T06:28:07.292022Z",
          "shell.execute_reply.started": "2025-07-29T06:28:07.279524Z",
          "shell.execute_reply": "2025-07-29T06:28:07.291307Z"
        },
        "id": "6YQdKny8rW5q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>MODEL TRAINING</b></font>"
      ],
      "metadata": {
        "id": "BdgBsqja2vFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through all different datasets and their corresponding head is trained.\n",
        "# fine-tuning is performed on the backbone network for all the datasets\n",
        "# optimizer and others initializations was perfom independently all the datasets\n",
        "# Naming convention should be uniform otherwise code will not work\n",
        "for head in HEADS:\n",
        "    # data loading and training ready format\n",
        "    print(f\"** TRAINING for {head}.csv **\")\n",
        "    file = f'/content/drive/MyDrive/cifar10_binary/{head}_train.csv'\n",
        "    data_loader = create_training_loader(file, upsampling = True)\n",
        "    # Define the optimizer\n",
        "    # Idea borrowed from Research paper titled as \"Improving Generalization Performance by Switching from Adam to SGD\"\n",
        "    if PRETRAINING:\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum = 0.9, weight_decay = L2_PENALTY)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = L2_PENALTY)\n",
        "\n",
        "    # Define a learning rate scheduler\n",
        "    scheduler = StepLR(optimizer, step_size = STEPSIZE, gamma = GAMMA)  # Adjust step_size and gamma as needed\n",
        "\n",
        "    MIN_LOSS = float('inf')\n",
        "    # TRAINING LOOP\n",
        "    for epoch in range(EPOCHS):\n",
        "        print('-'*70)\n",
        "        # Define the total number of batches in the loader\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # setting model stage to training\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
        "            # shifting to MPS\n",
        "            # Shift to MPS and then cast to float32\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()  # Moved this line here to avoid accumulating gradients\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                # Forward pass\n",
        "                outputs = model(images, head).squeeze()  # Squeeze to remove extra dimensions\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            cleaning_memory() # cleaning memory\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / (batch_idx + 1)}\")\n",
        "        print('TRAINING DATA PERFORMANCE \\n', calculate_classification_accuracy(data_loader, model, head))\n",
        "        # Update the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "        if SAVE_CHECKPOINTS:\n",
        "            checkpointmodel = '{}/epoch_{}_{}.pth'.format(CHECKPOINTDIR, epoch + 1, datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
        "            torch.save(model.state_dict(), checkpointmodel)\n",
        "\n",
        "        # Check if this epoch had the minimum loss\n",
        "        if total_loss < MIN_LOSS:\n",
        "            MIN_LOSS = total_loss\n",
        "            best_model = model.state_dict()\n",
        "            # Save the best model\n",
        "            if best_model is not None:\n",
        "                print('Saving Best Model: ', MODEL_SAVED)\n",
        "                torch.save(best_model, MODEL_SAVED)\n",
        "\n",
        "    ################################"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:28:07.292688Z",
          "iopub.execute_input": "2025-07-29T06:28:07.292893Z",
          "iopub.status.idle": "2025-07-29T06:41:58.789838Z",
          "shell.execute_reply.started": "2025-07-29T06:28:07.292869Z",
          "shell.execute_reply": "2025-07-29T06:41:58.788838Z"
        },
        "id": "VyLtn6J2rW5x",
        "outputId": "3a67a660-7c7d-44ae-db4f-d601c7ec6d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "** TRAINING for with_one.csv **\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n----------------------------------------------------------------------\nEpoch 1/5, Loss: 0.6656668522726681\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.96      0.90      0.93      7484\n         1.0       0.91      0.96      0.93      7516\n\n    accuracy                           0.93     15000\n   macro avg       0.93      0.93      0.93     15000\nweighted avg       0.93      0.93      0.93     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 2/5, Loss: 0.1446297260285434\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.96      0.98      0.97      7534\n         1.0       0.98      0.96      0.97      7466\n\n    accuracy                           0.97     15000\n   macro avg       0.97      0.97      0.97     15000\nweighted avg       0.97      0.97      0.97     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 3/5, Loss: 0.0609320358894134\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.96      0.99      0.98      7486\n         1.0       0.99      0.96      0.98      7514\n\n    accuracy                           0.98     15000\n   macro avg       0.98      0.98      0.98     15000\nweighted avg       0.98      0.98      0.98     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 4/5, Loss: 0.02986165231302917\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00      7409\n         1.0       1.00      1.00      1.00      7591\n\n    accuracy                           1.00     15000\n   macro avg       1.00      1.00      1.00     15000\nweighted avg       1.00      1.00      1.00     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 5/5, Loss: 0.01125410833135563\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00      7454\n         1.0       1.00      1.00      1.00      7546\n\n    accuracy                           1.00     15000\n   macro avg       1.00      1.00      1.00     15000\nweighted avg       1.00      1.00      1.00     15000\n\nSaving Best Model:  results/bestmodel.pth\n** TRAINING for with_two.csv **\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n----------------------------------------------------------------------\nEpoch 1/5, Loss: 0.6939283311367035\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.73      0.77      0.75      7419\n         1.0       0.76      0.72      0.74      7581\n\n    accuracy                           0.74     15000\n   macro avg       0.74      0.74      0.74     15000\nweighted avg       0.74      0.74      0.74     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 2/5, Loss: 0.47426007233433803\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.90      0.67      0.77      7472\n         1.0       0.74      0.93      0.82      7528\n\n    accuracy                           0.80     15000\n   macro avg       0.82      0.80      0.80     15000\nweighted avg       0.82      0.80      0.80     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 3/5, Loss: 0.35578316677424865\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.94      0.80      0.86      7501\n         1.0       0.83      0.95      0.88      7499\n\n    accuracy                           0.87     15000\n   macro avg       0.88      0.87      0.87     15000\nweighted avg       0.88      0.87      0.87     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 4/5, Loss: 0.2094378552194369\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.95      0.94      0.94      7539\n         1.0       0.94      0.95      0.94      7461\n\n    accuracy                           0.94     15000\n   macro avg       0.94      0.94      0.94     15000\nweighted avg       0.94      0.94      0.94     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 5/5, Loss: 0.12278999239837719\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.97      0.95      0.96      7384\n         1.0       0.96      0.97      0.97      7616\n\n    accuracy                           0.96     15000\n   macro avg       0.97      0.96      0.96     15000\nweighted avg       0.97      0.96      0.96     15000\n\nSaving Best Model:  results/bestmodel.pth\n** TRAINING for with_three.csv **\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n----------------------------------------------------------------------\nEpoch 1/5, Loss: 0.3464217591967623\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.94      0.89      0.91      7516\n         1.0       0.90      0.94      0.92      7484\n\n    accuracy                           0.92     15000\n   macro avg       0.92      0.92      0.92     15000\nweighted avg       0.92      0.92      0.92     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 2/5, Loss: 0.1499614735149731\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.93      0.97      0.95      7438\n         1.0       0.97      0.93      0.95      7562\n\n    accuracy                           0.95     15000\n   macro avg       0.95      0.95      0.95     15000\nweighted avg       0.95      0.95      0.95     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 3/5, Loss: 0.10941099819048482\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       0.97      0.97      0.97      7508\n         1.0       0.97      0.97      0.97      7492\n\n    accuracy                           0.97     15000\n   macro avg       0.97      0.97      0.97     15000\nweighted avg       0.97      0.97      0.97     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 4/5, Loss: 0.05413037012489039\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       1.00      0.98      0.99      7589\n         1.0       0.98      1.00      0.99      7411\n\n    accuracy                           0.99     15000\n   macro avg       0.99      0.99      0.99     15000\nweighted avg       0.99      0.99      0.99     15000\n\nSaving Best Model:  results/bestmodel.pth\n----------------------------------------------------------------------\nEpoch 5/5, Loss: 0.03273457229547834\nTRAINING DATA PERFORMANCE \n               precision    recall  f1-score   support\n\n         0.0       1.00      0.99      0.99      7532\n         1.0       0.99      1.00      0.99      7468\n\n    accuracy                           0.99     15000\n   macro avg       0.99      0.99      0.99     15000\nweighted avg       0.99      0.99      0.99     15000\n\nSaving Best Model:  results/bestmodel.pth\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>MODEL EVALUATION</b></font>"
      ],
      "metadata": {
        "id": "vxX71acS21N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading best model\n",
        "model.load_state_dict(torch.load(MODEL_SAVED, weights_only = True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:41:58.791181Z",
          "iopub.execute_input": "2025-07-29T06:41:58.791449Z",
          "iopub.status.idle": "2025-07-29T06:41:59.108866Z",
          "shell.execute_reply.started": "2025-07-29T06:41:58.791422Z",
          "shell.execute_reply": "2025-07-29T06:41:59.108091Z"
        },
        "id": "W2fPGxOSrW5y",
        "outputId": "40b9fb5c-a21d-49f6-af0d-261d2a381f61"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for head in HEADS:\n",
        "    print(f\"** Peformance **\")\n",
        "    for set_name in ['train', 'test']:\n",
        "        file = f'/content/drive/MyDrive/cifar10_binary/{head}_{set_name}.csv'\n",
        "        print(f\"Dataset: {set_name}\")\n",
        "        data_loader = create_training_loader(file,\n",
        "                                             upsampling = False)# without upsampling, used to report exact performance on the training data\n",
        "        print(calculate_classification_accuracy(data_loader, model, head))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T06:41:59.109728Z",
          "iopub.execute_input": "2025-07-29T06:41:59.109971Z",
          "iopub.status.idle": "2025-07-29T06:42:12.707129Z",
          "shell.execute_reply.started": "2025-07-29T06:41:59.109954Z",
          "shell.execute_reply": "2025-07-29T06:42:12.706307Z"
        },
        "id": "4QcaWPcbrW5z",
        "outputId": "715fb720-464e-4a3e-9e9e-8e9b2236d324"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "** Peformance **\nDataset: train\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       0.65      0.64      0.65     10000\n         1.0       0.30      0.30      0.30      5000\n\n    accuracy                           0.53     15000\n   macro avg       0.47      0.47      0.47     15000\nweighted avg       0.53      0.53      0.53     15000\n\nDataset: test\n::: DATA DETAILS :::\n- Number of Samples: 3000\n- LABEL DISTRIBUTION: \n LABEL\n0    2000\n1    1000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       0.65      0.65      0.65      2000\n         1.0       0.29      0.29      0.29      1000\n\n    accuracy                           0.53      3000\n   macro avg       0.47      0.47      0.47      3000\nweighted avg       0.53      0.53      0.53      3000\n\n** Peformance **\nDataset: train\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       0.75      0.83      0.79     10000\n         1.0       0.56      0.44      0.49      5000\n\n    accuracy                           0.70     15000\n   macro avg       0.66      0.63      0.64     15000\nweighted avg       0.69      0.70      0.69     15000\n\nDataset: test\n::: DATA DETAILS :::\n- Number of Samples: 3000\n- LABEL DISTRIBUTION: \n LABEL\n0    2000\n1    1000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       0.73      0.81      0.77      2000\n         1.0       0.51      0.39      0.44      1000\n\n    accuracy                           0.67      3000\n   macro avg       0.62      0.60      0.60      3000\nweighted avg       0.65      0.67      0.66      3000\n\n** Peformance **\nDataset: train\n::: DATA DETAILS :::\n- Number of Samples: 15000\n- LABEL DISTRIBUTION: \n LABEL\n0    10000\n1     5000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.99      0.99     10000\n         1.0       0.98      1.00      0.99      5000\n\n    accuracy                           0.99     15000\n   macro avg       0.99      0.99      0.99     15000\nweighted avg       0.99      0.99      0.99     15000\n\nDataset: test\n::: DATA DETAILS :::\n- Number of Samples: 3000\n- LABEL DISTRIBUTION: \n LABEL\n0    2000\n1    1000\nName: count, dtype: int64\n              precision    recall  f1-score   support\n\n         0.0       0.93      0.95      0.94      2000\n         1.0       0.90      0.86      0.88      1000\n\n    accuracy                           0.92      3000\n   macro avg       0.92      0.91      0.91      3000\nweighted avg       0.92      0.92      0.92      3000\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'><b>OBSERVATION</b></font>"
      ],
      "metadata": {
        "id": "sPWQfu-a4VBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Sequential training\n",
        "* The output is different for different task but have common feature extractor\n",
        "* From results it looks like new training phase overwrites the learned parameters, especially in the shared layers.\n",
        "* Leads to the model performing well on the last-trained language, but forgetting previous ones.\n",
        "* This sets the stage for a classical problem called Catastrophic Forgetting which we encountered here."
      ],
      "metadata": {
        "id": "KaCwUJGT4lfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color = 'green'><b>Catastrophic Forgetting: </b></font> When we sequentially train a shared model on multiple tasks, each new training phase overwrites the learned parameters, especially in the shared layers. This leads to the model performing well on the last-trained language, but forgetting previous ones."
      ],
      "metadata": {
        "id": "goixDWUr52Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f056Arbm6R0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}